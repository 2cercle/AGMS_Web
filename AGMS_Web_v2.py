# -*- coding: utf-8 -*-
"""
AGMS Sensor Analysis Dashboard (Full Clarke Error Grid)
Powered by Streamlit
"""
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
from pykalman import KalmanFilter
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
import io
import platform

# -----------------------------------------------------------------------------
# [1] í˜ì´ì§€ ë° í°íŠ¸ ì„¤ì •
# -----------------------------------------------------------------------------
st.set_page_config(
    page_title="AGMS ì„¼ì„œ ë¶„ì„ê¸°",
    page_icon="ğŸ©¸",
    layout="wide"
)

# í•œê¸€ í°íŠ¸ ì„¤ì • (OSë³„ ìë™ ëŒ€ì‘)
system_name = platform.system()
if system_name == 'Windows':
    plt.rcParams['font.family'] = 'Malgun Gothic'
elif system_name == 'Darwin': # Mac
    plt.rcParams['font.family'] = 'AppleGothic'
else:
    plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['axes.unicode_minus'] = False

# -----------------------------------------------------------------------------
# [2] Helper í•¨ìˆ˜: Full Clarke Error Grid Logic
# -----------------------------------------------------------------------------
def get_clarke_zone(ref, pred):
    """
    Standard Clarke Error Grid Zone Definition
    """
    if ref == 0: return 'B' # 0 ë‚˜ëˆ„ê¸° ë°©ì§€

    abs_diff = abs(ref - pred)
    
    # Zone A: Referenceì˜ Â±20% ì´ë‚´ ë˜ëŠ” ì €í˜ˆë‹¹(70ë¯¸ë§Œ) êµ¬ê°„ì—ì„œ ì˜¤ì°¨ 15 ë¯¸ë§Œ
    # (í†µìƒì ì¸ ì‹œê°ì  ê¸°ì¤€ì¸ Â±20% ë¼ì¸ì„ ìš°ì„  ì ìš©)
    if abs_diff <= 0.2 * ref:
        return 'A'
    if ref < 70 and abs_diff <= 15: # ì €í˜ˆë‹¹ êµ¬ê°„ì˜ ì—„ê²©í•œ Aì¡´ ê¸°ì¤€ (ì„ íƒì )
        return 'A'

    # Zone E: ìœ„í—˜í•œ ì˜¤ì°¨ (ì €í˜ˆë‹¹/ê³ í˜ˆë‹¹ ë°˜ëŒ€ íŒë…)
    if (ref <= 70 and pred >= 180) or (ref >= 180 and pred <= 70):
        return 'E'
    
    # Zone D: ê°ì§€ ì‹¤íŒ¨ (Failure to detect)
    # ì‹¤ì œë¡œëŠ” ë²”ìœ„ ë°–ì¸ë° ì •ìƒ(70~180)ìœ¼ë¡œ ì˜ˆì¸¡í•œ ê²½ìš°
    if (ref >= 240 and 70 <= pred <= 180) or (ref <= 70 and 70 <= pred <= 180):
        return 'D'
    
    # Zone C: ê³¼ë„í•œ êµì • (Overcorrection)
    # A, D, Eê°€ ì•„ë‹Œ ì˜ì—­ ì¤‘, Refë³´ë‹¤ Predê°€ ê³¼ë„í•˜ê²Œ ë†’ê±°ë‚˜ ë‚®ì€ ê²½ìš°
    # ìƒë‹¨ C êµ¬ì—­: (ref >= 70 and pred > ref + 110) ? -> ì´ë¯¸ì§€ ê¸°ì¤€ ì‚¬ì„  ì˜ì—­
    # í•˜ë‹¨ C êµ¬ì—­: (pred < ref - 110) ?
    # Clarke Grid ì •ì˜ìƒ Bì™€ Cì˜ ê²½ê³„ëŠ” íŠ¹ì • ë¼ì¸ì´ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ê°„ëµí™”ëœ ë¡œì§ ëŒ€ì‹ 
    # D, Eê°€ ì•„ë‹ˆë©´ì„œ A ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ê²ƒ ì¤‘ ê²½í–¥ì„±ì„ ë´…ë‹ˆë‹¤.
    # (ì´ë¯¸ì§€ ê¸°ì¤€: A ì½˜ ë°–, D/E ë°•ìŠ¤ ë°–ì´ë©´ B ì•„ë‹ˆë©´ C)
    
    # ì‹œê°ì  ì´ë¯¸ì§€ì™€ ë§¤ì¹­í•˜ê¸° ìœ„í•œ Cì¡´ ë¡œì§ (Over-correction zone)
    # ìƒë‹¨ C: ì‹¤ì œê°’ì€ ë‚®ì€ë° ì˜ˆì¸¡ê°’ì´ Aì¡´ ìœ„ìª½ ë¼ì¸ë³´ë‹¤ í›¨ì”¬ ë†’ì„ ë•Œ
    # í•˜ë‹¨ C: ì‹¤ì œê°’ì€ ë†’ì€ë° ì˜ˆì¸¡ê°’ì´ Aì¡´ ì•„ë˜ìª½ ë¼ì¸ë³´ë‹¤ í›¨ì”¬ ë‚®ì„ ë•Œ
    if (pred > ref + 110) or (pred < ref - 110):  # ì¼ë°˜ì ì¸ Cì¡´ ì»·ì˜¤í”„
         return 'C'

    # Zone B: ì„ìƒì  ì¡°ì¹˜ê°€ í•„ìš” ì—†ëŠ” ì–‘ì„± ì˜¤ì°¨
    return 'B'

def plot_clarke_grid(y_test, y_pred, ax):
    """
    Matplotlib Axesì— ì™„ë²½í•œ Clarke Error Grid ë¼ì¸ê³¼ ì‚°ì ë„ë¥¼ ê·¸ë¦¬ëŠ” í•¨ìˆ˜
    """
    # 1. Zone íŒë³„
    zones = [get_clarke_zone(r, p) for r, p in zip(y_test, y_pred)]
    zone_counts = {z: zones.count(z) for z in ['A', 'B', 'C', 'D', 'E']}
    total = len(zones)
    
    # ìƒ‰ìƒ ë§µ (ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼: A=Red/Pink, B=Green/Lime, D=Blue etc. -> ìš”ì²­ ì´ë¯¸ì§€ì™€ ìœ ì‚¬í•˜ê²Œ)
    # (ì¼ë°˜ì ìœ¼ë¡œ A=Greenì´ ì§ê´€ì ì´ë‚˜, ìš”ì²­í•˜ì‹  ì´ë¯¸ì§€ëŠ” Aê°€ Red ê³„ì—´ì…ë‹ˆë‹¤. 
    #  ì—¬ê¸°ì„œëŠ” ê°€ë…ì„±ì„ ìœ„í•´ A=Green, B=Blue, error=Red ê³„ì—´ì„ ì¶”ì²œí•˜ì§€ë§Œ, 
    #  ì´ë¯¸ì§€ ë¶„ìœ„ê¸°ë¥¼ ì‚´ë ¤ Aë¥¼ ë‹ë³´ì´ê²Œ í•©ë‹ˆë‹¤.)
    colors = {'A': '#2ca02c', 'B': '#1f77b4', 'C': '#ff7f0e', 'D': '#d62728', 'E': '#9467bd'}
    
    # ì‚°ì ë„ ê·¸ë¦¬ê¸°
    for z in ['A', 'B', 'C', 'D', 'E']:
        mask = [zone == z for zone in zones]
        if sum(mask) > 0:
            ax.scatter(
                y_test[mask], y_pred[mask], 
                c=colors[z], s=25, alpha=0.6, edgecolors='white', linewidth=0.5,
                label=f'Zone {z}: {zone_counts[z]} ({zone_counts[z]/total*100:.1f}%)'
            )

    # 2. Grid Lines (ì´ë¯¸ì§€ì™€ ë™ì¼í•œ êµ¬ì„±)
    ax.set_title("Clarke Error Grid Analysis", fontsize=12, fontweight='bold')
    ax.set_xlabel("Reference Glucose (mg/dL)")
    ax.set_ylabel("Sensor Glucose (mg/dL)")
    
    # ì¶• ë²”ìœ„ (0~400)
    ax.set_xlim(0, 400)
    ax.set_ylim(0, 400)
    ax.set_aspect('equal')

    # (1) ê¸°ì¤€ì„  (y=x)
    ax.plot([0, 400], [0, 400], 'k--', lw=1.5, alpha=0.7)

    # (2) Zone A/B Boundary (Â±20%)
    # Upper Line: y = 1.2x
    ax.plot([0, 333.3], [0, 400], 'k-', lw=1) 
    # Lower Line: y = 0.8x
    ax.plot([0, 400], [0, 320], 'k-', lw=1)

    # (3) ìˆ˜í‰/ìˆ˜ì§ êµ¬ë¶„ì„  (The Boxes)
    # Horizontal y=180
    ax.plot([0, 400], [180, 180], 'k-', lw=1)
    # Horizontal y=70
    ax.plot([0, 400], [70, 70], 'k-', lw=1)
    
    # Vertical x=180
    ax.plot([180, 180], [0, 400], 'k-', lw=1)
    # Vertical x=70
    ax.plot([70, 70], [0, 400], 'k-', lw=1)
    # Vertical x=240 (Zone D boundary)
    ax.plot([240, 240], [70, 180], 'k-', lw=1)

    # (4) í…ìŠ¤íŠ¸ ë¼ë²¨ (ê·¸ë¦¬ë“œ ìœ„ì— êµ¬ì—­ í‘œì‹œ)
    ax.text(30, 10, 'E', fontsize=12, color='red', fontweight='bold') # Lower Left E
    ax.text(350, 350, 'A', fontsize=12, color='green', fontweight='bold')
    ax.text(280, 200, 'B', fontsize=10, color='blue')
    ax.text(150, 260, 'B', fontsize=10, color='blue')
    ax.text(350, 120, 'D', fontsize=10, color='red')
    ax.text(30, 120, 'D', fontsize=10, color='red')
    ax.text(30, 350, 'E', fontsize=12, color='red', fontweight='bold') # Upper Left E
    ax.text(130, 350, 'C', fontsize=10, color='orange')
    ax.text(350, 30, 'C', fontsize=10, color='orange')

    ax.legend(loc='upper left', fontsize='small', frameon=True)
    ax.grid(False) # ê¸°ë³¸ ê²©ìëŠ” ë„ê³  Clarke ë¼ì¸ë§Œ ê°•ì¡°

# -----------------------------------------------------------------------------
# [3] ë°ì´í„° ì²˜ë¦¬ ë¡œì§
# -----------------------------------------------------------------------------
@st.cache_data
def process_data(libre_file, sensor_files, lag_minutes, warmup_hours):
    # --- 1. ë¦¬ë¸Œë ˆ(Reference) ë°ì´í„° ë¡œë“œ ---
    try:
        if libre_file.name.endswith('.xlsx'):
            libre_df = pd.read_excel(libre_file)
        else:
            libre_df = pd.read_csv(libre_file, skiprows=1) 
            
        col_map = {
            'Device Timestamp': 'ts', 
            'Historic Glucose mg/dL': 'gl', 
            'Scan Glucose mg/dL': 'gl_scan',
            'Timestamp': 'ts', 
            'Glucose': 'gl'
        }
        libre_df = libre_df.rename(columns=lambda x: col_map.get(x, x))
        
        libre_df['ts'] = pd.to_datetime(libre_df['ts'], errors='coerce')
        libre_df = libre_df.dropna(subset=['ts'])
        
        if 'gl' not in libre_df.columns and 'gl_scan' in libre_df.columns:
            libre_df['gl'] = libre_df['gl_scan']
        
        libre_df['gl'] = pd.to_numeric(libre_df['gl'], errors='coerce').interpolate()
        libre_df = libre_df.sort_values('ts')
        
        # Lag ì ìš©
        libre_df['ts_merge'] = libre_df['ts'] - pd.Timedelta(minutes=lag_minutes)
        libre_df = libre_df.sort_values('ts_merge')
        
    except Exception as e:
        return None, None, f"ë¦¬ë¸Œë ˆ(ì •ë‹µì§€) íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"

    # --- 2. ì„¼ì„œ(Raw) ë°ì´í„° ë¡œë“œ ---
    sensor_list = []
    use_cols = ['experiment_date', 'value_current', 'value_ae', 'value_temperature']
    
    for sf in sensor_files:
        try:
            temp = pd.read_csv(sf, usecols=lambda c: c in use_cols)
            sensor_list.append(temp)
        except:
            pass

    if not sensor_list:
        return None, None, "ìœ íš¨í•œ ì„¼ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

    sensor_df = pd.concat(sensor_list, ignore_index=True)
    sensor_df['timestamp'] = pd.to_datetime(sensor_df['experiment_date'], errors='coerce')
    sensor_df = sensor_df.dropna(subset=['timestamp']).sort_values('timestamp')

    # ì „ì²˜ë¦¬ & ì¹¼ë§Œ í•„í„°
    cols = ['value_current', 'value_ae', 'value_temperature']
    sensor_df[cols] = sensor_df[cols].ffill().bfill()
    
    kf = KalmanFilter(initial_state_mean=0, n_dim_obs=1)
    for c in cols:
        sensor_df[f'{c}_kf'], _ = kf.smooth(sensor_df[c].values)

    # Warm-up ì œê±°
    start_t = sensor_df['timestamp'].min()
    sensor_df['hours_since_start'] = (sensor_df['timestamp'] - start_t).dt.total_seconds() / 3600.0
    sensor_df = sensor_df[sensor_df['hours_since_start'] > warmup_hours]
    
    if sensor_df.empty:
        return None, None, f"ì´ˆê¸° {warmup_hours}ì‹œê°„ ì œê±° í›„ ë‚¨ì€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

    # --- 3. ë°ì´í„° ë³‘í•© ---
    merged = pd.merge_asof(libre_df, sensor_df, left_on='ts_merge', right_on='timestamp',
                           direction='nearest', tolerance=pd.Timedelta('15min'))
    
    final_df = merged.dropna(subset=['gl', 'value_current_kf'])
    
    if final_df.empty:
        return None, None, "ë°ì´í„° ë§¤ì¹­ ì‹¤íŒ¨."
        
    return final_df, sensor_df, None

# -----------------------------------------------------------------------------
# [4] ì‚¬ì´ë“œë°” UI
# -----------------------------------------------------------------------------
with st.sidebar:
    st.header("ğŸ“‚ 1. ë°ì´í„° ì…ë ¥")
    uploaded_libre = st.file_uploader("1) ë¦¬ë¸Œë ˆ ë°ì´í„° (ì—‘ì…€/CSV)", type=['csv', 'xlsx'])
    uploaded_sensors = st.file_uploader("2) ì„¼ì„œ ë°ì´í„° (CSV, ë‹¤ì¤‘ ì„ íƒ)", type=['csv'], accept_multiple_files=True)
    
    st.header("âš™ï¸ 2. ë¶„ì„ ì„¤ì •")
    lag_min = st.number_input("ì‹œê°„ ì§€ì—° (ë¶„)", value=15, step=1)
    warmup_hr = st.number_input("ì´ˆê¸° ì œê±° (ì‹œê°„)", value=24, step=1)
    
    st.header("ğŸ“ 3. ë¦¬í¬íŠ¸ ì •ë³´")
    memo = st.text_input("ì‹¤í—˜ ë©”ëª¨", placeholder="ì‹¤í—˜ ë‚´ìš© ì…ë ¥")
    
    st.divider()
    run_btn = st.button("ë¶„ì„ ì‹¤í–‰ ğŸš€", type="primary", use_container_width=True)

# -----------------------------------------------------------------------------
# [5] ë©”ì¸ ëŒ€ì‹œë³´ë“œ
# -----------------------------------------------------------------------------
if run_btn:
    if uploaded_libre and uploaded_sensors:
        report_title = f"ğŸ“Š AGMS ë¶„ì„ ê²°ê³¼: {memo}" if memo else "ğŸ“Š AGMS ë¶„ì„ ê²°ê³¼"
        st.title(report_title)
        
        with st.spinner('ë°ì´í„° ë³‘í•© ë° AI ë¶„ì„ ì¤‘...'):
            df, _, err = process_data(uploaded_libre, uploaded_sensors, lag_min, warmup_hr)
            
            if err:
                st.error(err)
            else:
                # ëª¨ë¸ë§
                features = ['value_current_kf', 'value_ae_kf', 'value_temperature_kf', 'hours_since_start']
                X = df[features]
                y = df['gl']
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
                
                model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                
                # ì§€í‘œ ê³„ì‚°
                r2 = r2_score(y_test, y_pred)
                mard = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
                
                def check_15_15(yt, yp):
                    if yt < 100: return abs(yt - yp) <= 15
                    else: return abs(yt - yp) / yt <= 0.15
                acc_15 = (sum([check_15_15(yt, yp) for yt, yp in zip(y_test, y_pred)]) / len(y_test)) * 100
                
                # KPI í‘œì‹œ
                kpi1, kpi2, kpi3, kpi4 = st.columns(4)
                kpi1.metric("MARD (ì˜¤ì°¨ìœ¨)", f"{mard:.2f}%", delta_color="inverse")
                kpi2.metric("15/15% ì •í™•ë„", f"{acc_15:.2f}%")
                kpi3.metric("R-Squared", f"{r2:.4f}")
                kpi4.metric("ìƒ˜í”Œ ìˆ˜ (Test)", f"{len(y_test)}ê°œ")
                
                st.divider()

                # --- 1. í˜ˆë‹¹ ê·¸ë˜í”„ (Plotly) : ì‹¤ì œ í˜ˆë‹¹ ê¸°ì¤€ Zone í‘œì‹œ ---
                st.subheader("ğŸ“ˆ í˜ˆë‹¹ ê·¸ë˜í”„ (ì‹¤ì œ í˜ˆë‹¹ ê¸°ì¤€ í—ˆìš© ë²”ìœ„)")
                
                ref_values = y_test.values
                upper_bound = [r + 15 if r < 100 else r * 1.15 for r in ref_values]
                lower_bound = [r - 15 if r < 100 else r * 0.85 for r in ref_values]
                
                fig = go.Figure()

                # (1) Lower Bound
                fig.add_trace(go.Scatter(
                    x=y_test.index, y=lower_bound,
                    mode='lines', line=dict(width=0),
                    showlegend=False, hoverinfo='skip'
                ))

                # (2) Upper Bound (Actual Â±15%)
                fig.add_trace(go.Scatter(
                    x=y_test.index, y=upper_bound,
                    mode='lines', line=dict(width=0),
                    fill='tonexty', fillcolor='rgba(0, 100, 255, 0.1)',
                    name='í—ˆìš© ì˜¤ì°¨ ë²”ìœ„ (Actual Â±15%)',
                    hoverinfo='skip'
                ))

                # (3) Reference
                fig.add_trace(go.Scatter(
                    x=y_test.index, y=y_test,
                    mode='lines', name='ì‹¤ì œ í˜ˆë‹¹ (Reference)',
                    line=dict(color='black', width=2) 
                ))

                # (4) Predicted
                fig.add_trace(go.Scatter(
                    x=y_test.index, y=y_pred,
                    mode='lines', name='AI ì˜ˆì¸¡ (Predicted)',
                    line=dict(color='#d62728', width=2, dash='dot') 
                ))

                fig.update_layout(
                    height=500,
                    margin=dict(l=20, r=20, t=30, b=20),
                    hovermode="x unified",
                    legend=dict(orientation="h", y=1.05, x=0.5, xanchor='center')
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # --- 2. ìƒì„¸ ë¶„ì„ ê·¸ë˜í”„ (Clarke Grid & Error Dist) ---
                c1, c2 = st.columns(2)
                
                with c1:
                    # â˜… Clarke Error Grid
                    fig_clarke, ax = plt.subplots(figsize=(6, 6))
                    plot_clarke_grid(y_test.values, y_pred, ax)
                    st.pyplot(fig_clarke)
                    
                with c2:
                    st.markdown("##### ğŸ“Š ì˜¤ì°¨ ë¶„í¬ (Residuals)")
                    errors = y_pred - y_test
                    fig_hist, ax2 = plt.subplots(figsize=(6, 6))
                    sns.histplot(errors, kde=True, bins=25, color='orange', ax=ax2)
                    ax2.axvline(0, color='black', linestyle='--')
                    ax2.set_xlabel('Error (Predicted - Reference)')
                    ax2.set_ylabel('Frequency')
                    ax2.grid(True, alpha=0.3)
                    st.pyplot(fig_hist)
                
                # --- 3. ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ---
                st.subheader("ğŸ“¥ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ")
                
                res_df = df.copy()
                res_df['Predicted_Glucose'] = np.nan
                res_df.loc[y_test.index, 'Predicted_Glucose'] = y_pred
                res_df['Error_Diff'] = res_df['Predicted_Glucose'] - res_df['gl']
                res_df['Error_Pct'] = (res_df['Error_Diff'] / res_df['gl']) * 100
                
                # ê° í¬ì¸íŠ¸ì˜ Zoneë„ ì—‘ì…€ì— ì €ì¥
                zones = [get_clarke_zone(r, p) if pd.notnull(p) else np.nan 
                         for r, p in zip(res_df['gl'], res_df['Predicted_Glucose'])]
                res_df['Clarke_Zone'] = zones
                
                save_cols = ['ts', 'gl', 'Predicted_Glucose', 'Clarke_Zone', 'Error_Diff', 'Error_Pct'] + \
                            [c for c in res_df.columns if c not in ['ts', 'gl', 'Predicted_Glucose', 'Clarke_Zone', 'Error_Diff', 'Error_Pct']]
                res_df = res_df[save_cols]

                buffer = io.BytesIO()
                with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                    res_df.to_excel(writer, index=False, sheet_name='Raw_Data')
                    summary = pd.DataFrame({
                        'Item': ['Memo', 'R2', 'MARD', '15/15 Accuracy'],
                        'Value': [memo, r2, f"{mard:.2f}%", f"{acc_15:.2f}%"]
                    })
                    summary.to_excel(writer, index=False, sheet_name='Summary')
                    
                st.download_button(
                    label="ğŸ“Š ê²°ê³¼ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ (Zone í¬í•¨)",
                    data=buffer.getvalue(),
                    file_name=f"AGMS_Result_{memo}.xlsx" if memo else "AGMS_Result.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )

    else:
        st.warning("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
else:
    st.info("ğŸ‘ˆ íŒŒì¼ ì—…ë¡œë“œ í›„ 'ë¶„ì„ ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
