# -*- coding: utf-8 -*-
"""
AGMS Sensor Analysis Dashboard (Auto Lag Optimization + Full Clarke Grid)
Powered by Streamlit
"""
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
from pykalman import KalmanFilter
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
import io
import platform

# -----------------------------------------------------------------------------
# [1] í˜ì´ì§€ ë° í°íŠ¸ ì„¤ì •
# -----------------------------------------------------------------------------
st.set_page_config(
    page_title="AGMS ì„¼ì„œ ë¶„ì„ê¸°",
    page_icon="ğŸ©¸",
    layout="wide"
)

# í•œê¸€ í°íŠ¸ ì„¤ì •
system_name = platform.system()
if system_name == 'Windows':
    plt.rcParams['font.family'] = 'Malgun Gothic'
elif system_name == 'Darwin': # Mac
    plt.rcParams['font.family'] = 'AppleGothic'
else:
    plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['axes.unicode_minus'] = False

# -----------------------------------------------------------------------------
# [2] Helper í•¨ìˆ˜: Clarke Error Grid Logic
# -----------------------------------------------------------------------------
def get_clarke_zone(ref, pred):
    if ref == 0: return 'B'
    abs_diff = abs(ref - pred)
    
    # Zone A
    if abs_diff <= 0.2 * ref: return 'A'
    if ref < 70 and abs_diff <= 15: return 'A'

    # Zone E
    if (ref <= 70 and pred >= 180) or (ref >= 180 and pred <= 70): return 'E'
    
    # Zone D
    if (ref >= 240 and 70 <= pred <= 180) or (ref <= 70 and 70 <= pred <= 180): return 'D'
    
    # Zone C
    if (pred > ref + 110) or (pred < ref - 110): return 'C'

    # Zone B
    return 'B'

def plot_clarke_grid(y_test, y_pred, ax):
    zones = [get_clarke_zone(r, p) for r, p in zip(y_test, y_pred)]
    zone_counts = {z: zones.count(z) for z in ['A', 'B', 'C', 'D', 'E']}
    total = len(zones)
    
    colors = {'A': '#2ca02c', 'B': '#1f77b4', 'C': '#ff7f0e', 'D': '#d62728', 'E': '#9467bd'}
    
    for z in ['A', 'B', 'C', 'D', 'E']:
        mask = [zone == z for zone in zones]
        if sum(mask) > 0:
            ax.scatter(
                y_test[mask], y_pred[mask], 
                c=colors[z], s=25, alpha=0.6, edgecolors='white', linewidth=0.5,
                label=f'Zone {z}: {zone_counts[z]} ({zone_counts[z]/total*100:.1f}%)'
            )

    ax.set_title("Clarke Error Grid Analysis", fontsize=12, fontweight='bold')
    ax.set_xlabel("Reference Glucose (mg/dL)")
    ax.set_ylabel("Sensor Glucose (mg/dL)")
    ax.set_xlim(0, 400); ax.set_ylim(0, 400)
    ax.set_aspect('equal')

    # Grid Lines
    ax.plot([0, 400], [0, 400], 'k--', lw=1.5, alpha=0.7)
    ax.plot([0, 333.3], [0, 400], 'k-', lw=1) # y=1.2x
    ax.plot([0, 400], [0, 320], 'k-', lw=1)   # y=0.8x
    ax.plot([0, 400], [180, 180], 'k-', lw=1)
    ax.plot([0, 400], [70, 70], 'k-', lw=1)
    ax.plot([180, 180], [0, 400], 'k-', lw=1)
    ax.plot([70, 70], [0, 400], 'k-', lw=1)
    ax.plot([240, 240], [70, 180], 'k-', lw=1)

    # Zone Labels
    ax.text(30, 10, 'E', fontsize=12, color='red', fontweight='bold')
    ax.text(350, 350, 'A', fontsize=12, color='green', fontweight='bold')
    ax.text(280, 200, 'B', fontsize=10, color='blue')
    ax.text(350, 120, 'D', fontsize=10, color='red')
    ax.text(30, 350, 'E', fontsize=12, color='red', fontweight='bold')
    ax.text(130, 350, 'C', fontsize=10, color='orange')

    ax.legend(loc='upper left', fontsize='small', frameon=True)
    ax.grid(False)

# -----------------------------------------------------------------------------
# [3] ë°ì´í„° ì²˜ë¦¬ ë¡œì§ (ë¶„ë¦¬ ë° ìµœì í™”)
# -----------------------------------------------------------------------------

@st.cache_data
def load_and_clean_data(libre_file, sensor_files, warmup_hours):
    """
    1ë‹¨ê³„: íŒŒì¼ ë¡œë“œ ë° ê¸°ë³¸ ì •ì œ (Lag ì ìš© ì „ ë‹¨ê³„)
    """
    # --- 1. ë¦¬ë¸Œë ˆ ë¡œë“œ ---
    try:
        if libre_file.name.endswith('.xlsx'):
            libre_df = pd.read_excel(libre_file)
        else:
            libre_df = pd.read_csv(libre_file, skiprows=1)
            
        col_map = {
            'Device Timestamp': 'ts', 'Historic Glucose mg/dL': 'gl', 
            'Scan Glucose mg/dL': 'gl_scan', 'Timestamp': 'ts', 'Glucose': 'gl'
        }
        libre_df = libre_df.rename(columns=lambda x: col_map.get(x, x))
        libre_df['ts'] = pd.to_datetime(libre_df['ts'], errors='coerce')
        libre_df = libre_df.dropna(subset=['ts'])
        
        if 'gl' not in libre_df.columns and 'gl_scan' in libre_df.columns:
            libre_df['gl'] = libre_df['gl_scan']
            
        libre_df['gl'] = pd.to_numeric(libre_df['gl'], errors='coerce').interpolate()
        libre_df = libre_df.sort_values('ts')
    except Exception as e:
        return None, None, f"ë¦¬ë¸Œë ˆ íŒŒì¼ ì˜¤ë¥˜: {str(e)}"

    # --- 2. ì„¼ì„œ ë¡œë“œ ë° ì¹¼ë§Œ í•„í„° ---
    sensor_list = []
    use_cols = ['experiment_date', 'value_current', 'value_ae', 'value_temperature']
    
    for sf in sensor_files:
        try:
            sf.seek(0) # íŒŒì¼ í¬ì¸í„° ì´ˆê¸°í™” (ì¤‘ìš”)
            temp = pd.read_csv(sf, usecols=lambda c: c in use_cols)
            sensor_list.append(temp)
        except: pass

    if not sensor_list:
        return None, None, "ìœ íš¨í•œ ì„¼ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

    sensor_df = pd.concat(sensor_list, ignore_index=True)
    sensor_df['timestamp'] = pd.to_datetime(sensor_df['experiment_date'], errors='coerce')
    sensor_df = sensor_df.dropna(subset=['timestamp']).sort_values('timestamp')

    cols = ['value_current', 'value_ae', 'value_temperature']
    sensor_df[cols] = sensor_df[cols].ffill().bfill()
    
    kf = KalmanFilter(initial_state_mean=0, n_dim_obs=1)
    for c in cols:
        sensor_df[f'{c}_kf'], _ = kf.smooth(sensor_df[c].values)

    start_t = sensor_df['timestamp'].min()
    sensor_df['hours_since_start'] = (sensor_df['timestamp'] - start_t).dt.total_seconds() / 3600.0
    sensor_df = sensor_df[sensor_df['hours_since_start'] > warmup_hours]
    
    if sensor_df.empty:
        return None, None, f"Warm-up({warmup_hours}h) ì´í›„ ë°ì´í„° ì—†ìŒ"

    return libre_df, sensor_df, None

def merge_with_lag(libre_df, sensor_df, lag_minutes):
    """
    2ë‹¨ê³„: íŠ¹ì • Lagë¥¼ ì ìš©í•˜ì—¬ ë³‘í•© (ë°˜ë³µ í˜¸ì¶œìš©)
    """
    temp_libre = libre_df.copy()
    # ë¦¬ë¸Œë ˆ ì‹œê°„ì„ ë’¤ë¡œ ë‹¹ê¹€ = ì„¼ì„œê°€ ë¦¬ë¸Œë ˆë³´ë‹¤ ëŠ¦ê²Œ ë°˜ì‘í•¨ì„ ë³´ì •
    temp_libre['ts_merge'] = temp_libre['ts'] - pd.Timedelta(minutes=lag_minutes)
    temp_libre = temp_libre.sort_values('ts_merge')
    
    merged = pd.merge_asof(temp_libre, sensor_df, left_on='ts_merge', right_on='timestamp',
                           direction='nearest', tolerance=pd.Timedelta('15min'))
    
    return merged.dropna(subset=['gl', 'value_current_kf'])

def train_and_evaluate(df):
    """
    3ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ ë° ì •í™•ë„(15/15%) ë°˜í™˜
    """
    if df.empty or len(df) < 10: return 0, 0, None, None, None

    features = ['value_current_kf', 'value_ae_kf', 'value_temperature_kf', 'hours_since_start']
    X = df[features]
    y = df['gl']
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
    
    model = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1) # ì†ë„ë¥¼ ìœ„í•´ estimators ì¡°ì ˆ
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    
    def check_15_15(yt, yp):
        if yt < 100: return abs(yt - yp) <= 15
        else: return abs(yt - yp) / yt <= 0.15
    
    acc_15 = (sum([check_15_15(yt, yp) for yt, yp in zip(y_test, y_pred)]) / len(y_test)) * 100
    
    return acc_15, model, X_test, y_test, y_pred

# -----------------------------------------------------------------------------
# [4] ì‚¬ì´ë“œë°” UI
# -----------------------------------------------------------------------------
with st.sidebar:
    st.header("ğŸ“‚ 1. ë°ì´í„° ì…ë ¥")
    uploaded_libre = st.file_uploader("1) ë¦¬ë¸Œë ˆ ë°ì´í„° (ì—‘ì…€/CSV)", type=['csv', 'xlsx'])
    uploaded_sensors = st.file_uploader("2) ì„¼ì„œ ë°ì´í„° (CSV, ë‹¤ì¤‘ ì„ íƒ)", type=['csv'], accept_multiple_files=True)
    
    st.header("âš™ï¸ 2. ë¶„ì„ ì„¤ì •")
    
    # ìµœì í™” ì˜µì…˜ ì¶”ê°€
    use_auto_lag = st.checkbox("âœ… ìµœì  ì‹œê°„ ì§€ì—° ìë™ íƒìƒ‰", value=False, help="5~15ë¶„ ë²”ìœ„ì—ì„œ ì •í™•ë„ê°€ ê°€ì¥ ë†’ì€ ì‹œê°„ì„ ìë™ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤.")
    
    if use_auto_lag:
        st.info("â±ï¸ 5ë¶„ ~ 15ë¶„ ë²”ìœ„ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤.")
        lag_min = 0 # Placeholder
    else:
        lag_min = st.number_input("ì‹œê°„ ì§€ì—° (ë¶„)", value=15, step=1)
        
    warmup_hr = st.number_input("ì´ˆê¸° ì œê±° (ì‹œê°„)", value=24, step=1)
    
    st.header("ğŸ“ 3. ë¦¬í¬íŠ¸ ì •ë³´")
    memo = st.text_input("ì‹¤í—˜ ë©”ëª¨", placeholder="ì‹¤í—˜ ë‚´ìš© ì…ë ¥")
    
    st.divider()
    run_btn = st.button("ë¶„ì„ ì‹¤í–‰ ğŸš€", type="primary", use_container_width=True)

# -----------------------------------------------------------------------------
# [5] ë©”ì¸ ëŒ€ì‹œë³´ë“œ
# -----------------------------------------------------------------------------
if run_btn:
    if uploaded_libre and uploaded_sensors:
        report_title = f"ğŸ“Š AGMS ë¶„ì„ ê²°ê³¼: {memo}" if memo else "ğŸ“Š AGMS ë¶„ì„ ê²°ê³¼"
        st.title(report_title)
        
        # 1. ë°ì´í„° ë¡œë“œ (ê³µí†µ)
        with st.spinner('ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ì¤‘...'):
            libre_df, sensor_df, err = load_and_clean_data(uploaded_libre, uploaded_sensors, warmup_hr)
            
        if err:
            st.error(err)
        else:
            final_lag = lag_min
            final_df = None
            final_results = None # (acc, model, X_test, y_test, y_pred)
            
            # 2. ìë™ ìµœì í™” ë¡œì§
            if use_auto_lag:
                best_acc = -1
                best_lag = 5
                
                progress_text = "ìµœì  ì‹œê°„ ì§€ì—°(Lag) íƒìƒ‰ ì¤‘... (5~15ë¶„)"
                my_bar = st.progress(0, text=progress_text)
                
                # íƒìƒ‰ ë²”ìœ„: 5ë¶„ ~ 15ë¶„
                search_range = range(5, 16)
                total_steps = len(search_range)
                
                for i, temp_lag in enumerate(search_range):
                    # Merge
                    temp_df = merge_with_lag(libre_df, sensor_df, temp_lag)
                    # Train & Eval
                    acc, model, xt, yt, yp = train_and_evaluate(temp_df)
                    
                    if acc > best_acc:
                        best_acc = acc
                        best_lag = temp_lag
                        final_df = temp_df
                        final_results = (acc, model, xt, yt, yp)
                    
                    my_bar.progress((i + 1) / total_steps, text=f"Lag {temp_lag}ë¶„ í…ŒìŠ¤íŠ¸ ì¤‘... (í˜„ì¬ ìµœê³  ì •í™•ë„: {best_acc:.2f}%)")
                
                my_bar.empty()
                st.success(f"ğŸ¯ ìµœì  ì§€ì—° ì‹œê°„ ë°œê²¬: **{best_lag}ë¶„** (15/15% ì •í™•ë„: {best_acc:.2f}%)")
                final_lag = best_lag
                
            else:
                # ìˆ˜ë™ ëª¨ë“œ
                with st.spinner('ë¶„ì„ ìˆ˜í–‰ ì¤‘...'):
                    final_df = merge_with_lag(libre_df, sensor_df, lag_min)
                    acc, model, xt, yt, yp = train_and_evaluate(final_df)
                    final_results = (acc, model, xt, yt, yp)
                    
            # 3. ê²°ê³¼ ì‹œê°í™” (ê³µí†µ)
            if final_results and final_results[3] is not None:
                acc_15, model, X_test, y_test, y_pred = final_results
                
                # R2, MARD ì¬ê³„ì‚° (ìµœì¢… ëª¨ë¸ ê¸°ì¤€)
                r2 = r2_score(y_test, y_pred)
                mard = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
                
                # KPI í‘œì‹œ
                kpi1, kpi2, kpi3, kpi4 = st.columns(4)
                kpi1.metric("MARD (ì˜¤ì°¨ìœ¨)", f"{mard:.2f}%", delta_color="inverse")
                kpi2.metric("15/15% ì •í™•ë„", f"{acc_15:.2f}%")
                kpi3.metric("R-Squared", f"{r2:.4f}")
                kpi4.metric(f"ì ìš©ëœ ì§€ì—° ì‹œê°„", f"{final_lag}ë¶„")
                
                st.divider()

                # --- Graph 1: Plotly Time Series ---
                st.subheader(f"ğŸ“ˆ í˜ˆë‹¹ ê·¸ë˜í”„ (Lag {final_lag}ë¶„ ì ìš©)")
                ref_values = y_test.values
                upper_bound = [r + 15 if r < 100 else r * 1.15 for r in ref_values]
                lower_bound = [r - 15 if r < 100 else r * 0.85 for r in ref_values]
                
                fig = go.Figure()
                fig.add_trace(go.Scatter(x=y_test.index, y=lower_bound, mode='lines', line=dict(width=0), showlegend=False, hoverinfo='skip'))
                fig.add_trace(go.Scatter(x=y_test.index, y=upper_bound, mode='lines', line=dict(width=0), fill='tonexty', fillcolor='rgba(0, 100, 255, 0.1)', name='í—ˆìš© ì˜¤ì°¨ ë²”ìœ„', hoverinfo='skip'))
                fig.add_trace(go.Scatter(x=y_test.index, y=y_test, mode='lines', name='ì‹¤ì œ í˜ˆë‹¹ (Reference)', line=dict(color='black', width=2)))
                fig.add_trace(go.Scatter(x=y_test.index, y=y_pred, mode='lines', name='AI ì˜ˆì¸¡ (Predicted)', line=dict(color='#d62728', width=2, dash='dot')))
                fig.update_layout(height=500, margin=dict(l=20, r=20, t=30, b=20), hovermode="x unified", legend=dict(orientation="h", y=1.05, x=0.5, xanchor='center'))
                st.plotly_chart(fig, use_container_width=True)
                
                # --- Graph 2: Clarke & Hist ---
                c1, c2 = st.columns(2)
                with c1:
                    fig_clarke, ax = plt.subplots(figsize=(6, 6))
                    plot_clarke_grid(y_test.values, y_pred, ax)
                    st.pyplot(fig_clarke)
                with c2:
                    st.markdown("##### ğŸ“Š ì˜¤ì°¨ ë¶„í¬ (Residuals)")
                    errors = y_pred - y_test
                    fig_hist, ax2 = plt.subplots(figsize=(6, 6))
                    sns.histplot(errors, kde=True, bins=25, color='orange', ax=ax2)
                    ax2.axvline(0, color='black', linestyle='--')
                    ax2.set_xlabel('Error (Predicted - Reference)')
                    st.pyplot(fig_hist)
                
                # --- Excel Download ---
                st.subheader("ğŸ“¥ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ")
                res_df = final_df.copy()
                res_df['Predicted_Glucose'] = np.nan
                res_df.loc[y_test.index, 'Predicted_Glucose'] = y_pred
                res_df['Error_Diff'] = res_df['Predicted_Glucose'] - res_df['gl']
                res_df['Error_Pct'] = (res_df['Error_Diff'] / res_df['gl']) * 100
                zones = [get_clarke_zone(r, p) if pd.notnull(p) else np.nan for r, p in zip(res_df['gl'], res_df['Predicted_Glucose'])]
                res_df['Clarke_Zone'] = zones
                
                save_cols = ['ts', 'gl', 'Predicted_Glucose', 'Clarke_Zone', 'Error_Diff', 'Error_Pct'] + [c for c in res_df.columns if c not in ['ts', 'gl', 'Predicted_Glucose', 'Clarke_Zone', 'Error_Diff', 'Error_Pct']]
                res_df = res_df[save_cols]

                buffer = io.BytesIO()
                with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                    res_df.to_excel(writer, index=False, sheet_name='Raw_Data')
                    summary = pd.DataFrame({
                        'Item': ['Memo', 'Applied Lag (min)', 'R2', 'MARD', '15/15 Accuracy'],
                        'Value': [memo, final_lag, r2, f"{mard:.2f}%", f"{acc_15:.2f}%"]
                    })
                    summary.to_excel(writer, index=False, sheet_name='Summary')
                    
                st.download_button(label="ğŸ“Š ê²°ê³¼ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", data=buffer.getvalue(), file_name=f"AGMS_Result_{memo}.xlsx" if memo else "AGMS_Result.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", use_container_width=True)
            else:
                st.error("ë¶„ì„í•  ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    else:
        st.warning("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
else:
    st.info("ğŸ‘ˆ íŒŒì¼ ì—…ë¡œë“œ í›„ 'ë¶„ì„ ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
